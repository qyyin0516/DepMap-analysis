{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1bac57-71ad-4459-8ff3-06adc632adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 21:49:21.763271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-04 21:49:21.763340: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home1/yinq/.local/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from pathway_hierarchy import *\n",
    "from neural_network import *\n",
    "from utils import *\n",
    "\n",
    "random.seed(1999)\n",
    "np.random.seed(1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3bb99b-02fe-40a0-b7ba-219933220219",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gene_file_name = \"../../dataset/InputGene/temp.csv\"\n",
    "output_performance_file_name = \"3008FunctionalGene.csv\"\n",
    "if_functional = True\n",
    "start_idx = 0\n",
    "end_idx = 15\n",
    "n_hidden = 3\n",
    "learning_rate = 0.01\n",
    "minibatch_size = 128\n",
    "num_epochs = 100\n",
    "gamma = 0.0001\n",
    "pathway_AUC_cutoff = 0.6\n",
    "Dp_cutoff = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c3f3a5-aea4-46eb-acab-890444890972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_24623249/ipykernel_35707/3586628807.py:2: DtypeWarning: Columns (49,50,51,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mutation = pd.read_csv(\"../../dataset/OmicsSomaticMutations.csv\")\n",
      "/tmp/SLURM_24623249/ipykernel_35707/3586628807.py:7: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clinvar = pd.read_csv(\"../../dataset/ClinVar/ClinVar_variant_summary.txt\", delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../dataset/CRISPRGeneEffect.csv\", index_col=0)\n",
    "mutation = pd.read_csv(\"../../dataset/OmicsSomaticMutations.csv\")\n",
    "mutation = mutation[mutation['VariantType'] == 'SNP']\n",
    "mutation = mutation[['Chrom', 'Pos', 'HugoSymbol', 'ModelID']]\n",
    "\n",
    "if if_functional:\n",
    "    clinvar = pd.read_csv(\"../../dataset/ClinVar/ClinVar_variant_summary.txt\", delimiter='\\t')\n",
    "    clinvar = clinvar[clinvar['Assembly'] == \"GRCh38\"]\n",
    "    clinvar = clinvar[clinvar['Type'] == \"single nucleotide variant\"]\n",
    "    pathogenicity = pd.read_csv(\"../../dataset/ClinVar/pathogenicity.csv\", index_col=0)\n",
    "    pathogenetic_type = list(pathogenicity[pathogenicity['Pathogenicity'] == 'Y']['Category'])\n",
    "    mutation_patho = clinvar[clinvar['ClinicalSignificance'].isin(pathogenetic_type)]\n",
    "    mutation_patho = mutation_patho[[\"Chromosome\", \"Start\", \"GeneSymbol\"]]\n",
    "    mutation_patho['Chromosome'] = mutation_patho['Chromosome'].apply(lambda x: 'chr' + str(x))\n",
    "    mutation['ID'] = mutation['Chrom'] + '-' + mutation['Pos'].astype(str)\n",
    "    mutation_patho['ID'] = mutation_patho['Chromosome'] + '-' + mutation_patho['Start'].astype(str)\n",
    "    mutation = mutation.sort_values(by=['ID'])\n",
    "    mutation_patho = mutation_patho.sort_values(by=['ID'])\n",
    "    mutation = pd.merge(mutation, mutation_patho, on='ID', how='inner')\n",
    "mutation = mutation[['ModelID', 'HugoSymbol']]\n",
    "mutation = mutation.sort_values([\"HugoSymbol\", \"ModelID\"])\n",
    "mutation = mutation.drop_duplicates()\n",
    "mutation.index = range(mutation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29fad16-b4ff-44e7-b826-96050d661d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_col = list(data.columns)\n",
    "for i in range(len(gene_col)):\n",
    "    gene_col[i] = gene_col[i].split(' ')[0]\n",
    "data.columns = gene_col\n",
    "gene_info = pd.read_csv(\"../../dataset/InputGene/ScreenedGene.csv\")\n",
    "gene_info = gene_info.drop_duplicates(subset=['From'], keep='first')\n",
    "data = data[gene_info.iloc[:, 0]]\n",
    "data.columns = gene_info.iloc[:, 1]\n",
    "ifnull = data.isnull().sum()\n",
    "data = data[ifnull[ifnull == 0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d112ec5f-20dc-4896-82e6-268303a927e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if gene_type == \"single\":\n",
    "mut_gene = pd.read_csv(input_gene_file_name, header=None)\n",
    "label = pd.DataFrame(data=0, index=mut_gene.iloc[:, 0], columns=data.index)\n",
    "for i in range(label.shape[0]):\n",
    "    mut_sub = mutation[mutation['HugoSymbol'] == mut_gene.iloc[i, 0]]\n",
    "    model_sub = list(set(mut_sub['ModelID']) & set(label.columns))\n",
    "    label.iloc[i][model_sub] = 1\n",
    "# elif gene_type == \"pair\":\n",
    "#     mut_gene = pd.read_csv(input_gene_path)\n",
    "#     mut_gene = mut_gene.iloc[start_idx:end_idx, :]\n",
    "#     label = pd.DataFrame(data='OO', index=mut_gene.iloc[:, 0] + '/' + mut_gene.iloc[:, 1], columns=data.index)\n",
    "#     for i in range(label.shape[0]):\n",
    "#         mut1 = mutation[mutation['HugoSymbol'] == mut_gene.iloc[i, 0]]\n",
    "#         model1 = list(set(mut1['ModelID']) & set(label.columns))\n",
    "#         mut2 = mutation[mutation['HugoSymbol'] == mut_gene.iloc[i, 1]]\n",
    "#         model2 = list(set(mut2['ModelID']) & set(label.columns))\n",
    "#         label.iloc[i][list(set(model2) - set(model1))] = 'OI'\n",
    "#         label.iloc[i][list(set(model1) - set(model2))] = 'IO'\n",
    "#         label.iloc[i][list(set(model1) & set(model2))] = 'II'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ae46e-3135-46c6-9988-e923079d308f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a1bfdd-1ca1-458b-b8f9-a34c1944911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellLine = pd.read_csv(\"../../dataset/Model.csv\", index_col=0)\n",
    "tissues = cellLine['OncotreeLineage'].unique()\n",
    "tissue_AUC = pd.DataFrame(index=sorted(tissues))\n",
    "tissue_count = pd.DataFrame(index=sorted(tissues))\n",
    "tissue_count_1 = pd.DataFrame(index=sorted(tissues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3ca6ac-0a65-4223-9ea5-f42417c8398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 1 hidden layers.\n",
      "WARNING:tensorflow:From /home1/yinq/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 21:53:30.835207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-12-04 21:53:30.835252: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-12-04 21:53:30.835291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b14-03.hpc.usc.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-12-04 21:53:30.835518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 21:53:30.851376: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:55: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:58: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 2 hidden layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:55: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:58: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 3 hidden layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:55: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_24623249/ipykernel_35707/2012253101.py:58: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    }
   ],
   "source": [
    "for i in range(start_idx, end_idx):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, label.iloc[i, :], test_size=0.25)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    pathway_genes = get_gene_pathways(\"../../dataset/reactome/Ensembl2Reactome_All_Levels.txt\", species='human')\n",
    "    pathway_names = '../../dataset/reactome/ReactomePathways.txt'\n",
    "    relations_file_name = '../../dataset/reactome/ReactomePathwaysRelation.txt'\n",
    "    root_name = [0, 1]\n",
    "    masking, layers_node, gene_out = get_masking(pathway_names, pathway_genes, relations_file_name, x_train.T.index.tolist(), \n",
    "                                                root_name, n_hidden=n_hidden)\n",
    "    x_train = x_train.T.loc[gene_out, :]\n",
    "    x_test = x_test.T.loc[gene_out, :]\n",
    "    \n",
    "    if y_train.iloc[:, 0].sum() > 0:\n",
    "        dt = x_train\n",
    "        dt.loc['label'] = y_train.iloc[:, 0]\n",
    "        dt = dt.T\n",
    "        dt0 = dt[dt['label'] == 0]\n",
    "        dt1 = dt[dt['label'] == 1]\n",
    "        index = np.random.randint(len(dt1), size=int(len(dt) - len(dt1)))\n",
    "        up_dt1 = dt1.iloc[list(index)]\n",
    "        up_dt = pd.concat([up_dt1, dt0])\n",
    "        y_train = pd.DataFrame(up_dt['label'])\n",
    "        x_train = up_dt\n",
    "        del x_train['label']\n",
    "        x_train = x_train.T\n",
    "    \n",
    "    y_train_pred_df = pd.DataFrame(data=0, index=x_train.columns, columns=list(range(2, len(masking) + 2)))\n",
    "    y_test_pred_df = pd.DataFrame(data=0, index=x_test.columns, columns=list(range(2, len(masking) + 2)))\n",
    "    activation_output = {}\n",
    "    for output_layer in range(2, len(masking) + 2):\n",
    "        print(\"Current neural network has \" + str(output_layer - 1) + \" hidden layers.\")\n",
    "        output_train, output_test = model(np.array(x_train),\n",
    "                                          one_hot_coding(y_train),\n",
    "                                          np.array(x_test),\n",
    "                                          layers_node,\n",
    "                                          masking,\n",
    "                                          output_layer,\n",
    "                                          learning_rate=learning_rate,\n",
    "                                          minibatch_size=minibatch_size,\n",
    "                                          num_epochs=num_epochs,\n",
    "                                          gamma=gamma,\n",
    "                                          print_cost=False)\n",
    "        for j in range(len(output_train)):\n",
    "            if (j != output_layer - 1):\n",
    "                output_train[j + 1] = pd.DataFrame(data=output_train[j + 1],\n",
    "                                                   index=layers_node[len(layers_node) - 2 - j],\n",
    "                                                   columns=x_train.columns)\n",
    "            else:\n",
    "                output_train[j + 1] = pd.DataFrame(data=output_train[j + 1], index=[0, 1],\n",
    "                                                   columns=x_train.columns)\n",
    "        activation_output[output_layer] = output_train\n",
    "        y_train_pred, y_test_pred = get_predictions(output_train, output_test, output_layer)\n",
    "        y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
    "                                                            index=x_train.columns,\n",
    "                                                            columns=[output_layer])\n",
    "        y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n",
    "                                                           index=x_test.columns,\n",
    "                                                           columns=[output_layer])\n",
    "    y_train_pred_final = y_train_pred_df.T.mode().T.loc[x_train.columns, :][0]\n",
    "    y_test_pred_final = y_test_pred_df.T.mode().T.loc[x_test.columns, :][0]\n",
    "\n",
    "\n",
    "    tissues = cellLine.loc[y_test_pred_final.index, 'OncotreeLineage']\n",
    "    results_df = pd.DataFrame({\n",
    "        'y_test': y_test.iloc[:,0].values,\n",
    "        'y_test_pred': y_test_pred_final.values,\n",
    "        'tissue': tissues.values\n",
    "    })\n",
    "    auc_by_tissue = {}\n",
    "    for tissue, group in results_df.groupby('tissue'):\n",
    "        if len(group['y_test'].unique()) == 1:\n",
    "            auc_by_tissue[tissue] = None\n",
    "        else:\n",
    "            auc_by_tissue[tissue] = roc_auc_score(group['y_test'], group['y_test_pred'])\n",
    "            \n",
    "    auc_by_tissue = pd.DataFrame(list(auc_by_tissue.items()), columns=['tissue', 'AUC'])\n",
    "    auc_by_tissue = auc_by_tissue.sort_values(by='tissue')\n",
    "    tissue_AUC[label.index[i]] = tissue_AUC.index.map(auc_by_tissue.set_index('tissue')['AUC'])\n",
    "    tissue_count[label.index[i]] = tissue_count.index.map(results_df['tissue'].value_counts())\n",
    "    tissue_count_1[label.index[i]] = results_df[results_df['y_test'] == 1]['tissue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f70e5e-a8c1-456e-a2d0-917b9bddf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_AUC.to_csv(\"tissue_auc.csv\")\n",
    "tissue_count.to_csv(\"tissue_count.csv\")\n",
    "tissue_count_1.to_csv(\"tissue_count_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cc223-485e-431a-bf5c-0ebdc4c7e794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec4c5c-3545-4eef-8bce-539d15d58ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ad3649-d845-49a8-b462-8bb5ee00bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 1 hidden layers.\n",
      "WARNING:tensorflow:From /home1/yinq/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 09:48:46.658849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-10-18 09:48:46.658904: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-10-18 09:48:46.658952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b02-02.hpc.usc.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-10-18 09:48:46.659151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 09:48:46.682714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:56: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:59: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 2 hidden layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:56: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:59: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 3 hidden layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:56: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:59: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 1 hidden layers.\n",
      "Current neural network has 2 hidden layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:56: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:59: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:56: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
      "/tmp/SLURM_23999190/ipykernel_32759/3307076807.py:59: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current neural network has 3 hidden layers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/SLURM_23999190/ipykernel_32759/3307076807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current neural network has \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_layer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" hidden layers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         output_train, output_test = model(np.array(x_train),\n\u001b[0m\u001b[1;32m     36\u001b[0m                                           \u001b[0mone_hot_coding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/liangche_105/yinq/depmap/script/gene/neural_network.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, layers_node, masking, output_layer, learning_rate, num_epochs, minibatch_size, gamma, print_cost)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1453\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['auc', 'acc'])\n",
    "for i in range(start_idx, end_idx):\n",
    "#for i in range(label.shape[0]):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, label.iloc[i, :], test_size=0.25)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    pathway_genes = get_gene_pathways(\"../../dataset/reactome/Ensembl2Reactome_All_Levels.txt\", species='human')\n",
    "    pathway_names = '../../dataset/reactome/ReactomePathways.txt'\n",
    "    relations_file_name = '../../dataset/reactome/ReactomePathwaysRelation.txt'\n",
    "    root_name = [0, 1]\n",
    "    masking, layers_node, gene_out = get_masking(pathway_names, pathway_genes, relations_file_name, x_train.T.index.tolist(), \n",
    "                                                root_name, n_hidden=n_hidden)\n",
    "    x_train = x_train.T.loc[gene_out, :]\n",
    "    x_test = x_test.T.loc[gene_out, :]\n",
    "\n",
    "    if y_train.iloc[:, 0].sum() > 0:\n",
    "        dt = x_train\n",
    "        dt.loc['label'] = y_train.iloc[:, 0]\n",
    "        dt = dt.T\n",
    "        dt0 = dt[dt['label'] == 0]\n",
    "        dt1 = dt[dt['label'] == 1]\n",
    "        index = np.random.randint(len(dt1), size=int(len(dt) - len(dt1)))\n",
    "        up_dt1 = dt1.iloc[list(index)]\n",
    "        up_dt = pd.concat([up_dt1, dt0])\n",
    "        y_train = pd.DataFrame(up_dt['label'])\n",
    "        x_train = up_dt\n",
    "        del x_train['label']\n",
    "        x_train = x_train.T\n",
    "    \n",
    "    y_train_pred_df = pd.DataFrame(data=0, index=x_train.columns, columns=list(range(2, len(masking) + 2)))\n",
    "    y_test_pred_df = pd.DataFrame(data=0, index=x_test.columns, columns=list(range(2, len(masking) + 2)))\n",
    "    activation_output = {}\n",
    "    for output_layer in range(2, len(masking) + 2):\n",
    "        print(\"Current neural network has \" + str(output_layer - 1) + \" hidden layers.\")\n",
    "        output_train, output_test = model(np.array(x_train),\n",
    "                                          one_hot_coding(y_train),\n",
    "                                          np.array(x_test),\n",
    "                                          layers_node,\n",
    "                                          masking,\n",
    "                                          output_layer,\n",
    "                                          learning_rate=learning_rate,\n",
    "                                          minibatch_size=minibatch_size,\n",
    "                                          num_epochs=num_epochs,\n",
    "                                          gamma=gamma,\n",
    "                                          print_cost=False)\n",
    "        for j in range(len(output_train)):\n",
    "            if (j != output_layer - 1):\n",
    "                output_train[j + 1] = pd.DataFrame(data=output_train[j + 1],\n",
    "                                                   index=layers_node[len(layers_node) - 2 - j],\n",
    "                                                   columns=x_train.columns)\n",
    "            else:\n",
    "                output_train[j + 1] = pd.DataFrame(data=output_train[j + 1], index=[0, 1],\n",
    "                                                   columns=x_train.columns)\n",
    "        activation_output[output_layer] = output_train\n",
    "        y_train_pred, y_test_pred = get_predictions(output_train, output_test, output_layer)\n",
    "        y_train_pred_df.loc[:, output_layer] = pd.DataFrame(y_train_pred,\n",
    "                                                            index=x_train.columns,\n",
    "                                                            columns=[output_layer])\n",
    "        y_test_pred_df.loc[:, output_layer] = pd.DataFrame(y_test_pred,\n",
    "                                                           index=x_test.columns,\n",
    "                                                           columns=[output_layer])\n",
    "    y_train_pred_final = y_train_pred_df.T.mode().T.loc[x_train.columns, :][0]\n",
    "    y_test_pred_final = y_test_pred_df.T.mode().T.loc[x_test.columns, :][0]\n",
    "    # if gene_type == \"pair\":\n",
    "    #     y_train_pred_final[y_train_pred_final == 0] = 'II'\n",
    "    #     y_train_pred_final[y_train_pred_final == 1] = 'IO'\n",
    "    #     y_train_pred_final[y_train_pred_final == 2] = 'OI'\n",
    "    #     y_train_pred_final[y_train_pred_final == 3] = 'OO'\n",
    "    #     y_test_pred_final[y_test_pred_final == 0] = 'II'\n",
    "    #     y_test_pred_final[y_test_pred_final == 1] = 'IO'\n",
    "    #     y_test_pred_final[y_test_pred_final == 2] = 'OI'\n",
    "    #     y_test_pred_final[y_test_pred_final == 3] = 'OO'\n",
    "    result.loc[label.index[i]] = [manual_auc(y_test, y_test_pred_final),\n",
    "                                  accuracy_score(y_test, y_test_pred_final)]\n",
    "    result.to_csv(output_performance_file_name)\n",
    "\n",
    "    if result.iloc[(i - start_idx), 0] >= pathway_AUC_cutoff:\n",
    "        pathways = get_pathway_importance(y_train, activation_output, thr=Dp_cutoff)\n",
    "        pathways.to_csv(\"pathways_\" + label.index[i] + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2",
   "language": "python",
   "name": "py392"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
